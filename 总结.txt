This also means that the set can be diagrammed as a line of elements, giving it the name linear.
(total order)
1.
Thanks for the feedback and the interesting questions.
A:
The intuition is roughly as follows. Say, ask an agent i ($1<i<n$) who is a^*. How can we know whether it is lying? This is why we introduce the mechanism of choosing 3 randomly agents. To prove the property of truth-telling being a strict Nash equilibrium, if agent i is lying, there will be a positive probability that we can find that i is making irrational choice. So then we can do something about it. The hard case is when i is saying itself being a^*. However in this case, agent 1 also has a positive probability of being selected as one of the 3 random agents. Hence there would be at least two agents saying themselves to be a^*. We just ignore all of these 3 agents, and choose someone else. Consequently agent i in expectation will hurt itself, as someone strictly worse than it might get selected as a^*. As a summary, in the equilibrium of truth-telling, i only gets strictly worse by deviation. 
We would like to take the suggestion, and try our best to revise the paper to make it more intuitive. Thanks!
B:
That is an interesting extension. Of course for the total order to be well-defined, the true partial information jointly held by all agents should be able to recover the true underlying ordering. As a starting point, to get the total order, one at least should be able to figure out a^*. Intuitively, when asked an agent i who is the best among its associated subset, agent i would not answer someone strictly worse than itself. Would it tell someone strictly better but not the best in its subset? Intuitively it won't either. So the only case might be i saying itself. Hence the techniques of randomization and ignoring self-loop answers under certain circumstances might be helpful for this scenario. But it really needs more careful check and think to make it truly work.
C: We are glad to take the suggestion.
D: We believe some negative results still hold with other query models.
The first is that the last-ranked agent can always cheat. Hence without a negligible probability of swapping, strict Nash equilibria would not exist. This fact is almost irrelevant to what we ask in the mechanism. Lower bound still holds, as the number of possible answers cannot be more than n. Hence the decision tree only becomes deeper.
We are not sure of Theorem 1. But if everyone knows the total order, rather than the subset, the authors feel the results still hold, as revelation principle always helps focus on the truth-telling direct mechanism. Essentially the same argument would apply.
2.
Thanks for the feedback.
We are sorry to bring a game-theory flavor paper to NIPS. But "NIPS 17 call for papers" has a track for "Game Theory and Computational Economics." They are located at point 6 of that webpage. So that is why we submit it. Also game-theoretic stuff continues to emerge in the machine learning community. As a typical example, Generative adversarial networks are good applications of zero-sum games, which are then classic game-theoretic frameworks.
We introduced evolutionarily stable just to emphasize the importance of one of our results, i.e.,
the unique strict Nash equilibrium. One can refer to the literature and finds that our result is a little stronger than being evolutionarily stable. Actually by a similar argument, truth-telling is also the unique evolutionarily stable one. Intuitively, for any non-truth-telling equilibrium, when competing with truth-telling strategy, it would finally be invaded. The reason is at least agent 1 would like to adopt truth-telling. Consequently, other agents are more or less forced to be honest, because trying to lie never gives them strictly better payoff. Hence any equilibrium naturally "evolves" to truth-telling.
Sorry for the hard reading stuff of the plain text in Algorithm 1. These explanations are just added to make the algorithm more readable. They are not part of the algorithm. They are added to enable an easy access to what is happening. So we took several examples in the algorithm. We are very glad to take the suggestion, introducing them earlier in the paper. A thorough spell check will also be done later.
3.
Thanks for the thorough reading of the paper, and the affirmative evaluation.
We actually looked at the every single detail, and checked every aspect to make sure the proofs, and the results are thoroughly rigorous. Thanks for the appreciation of our effort.
As to the game-theory topic for NIPS, like our feedback to the second reviewer, NIPS calling for papers really has a track for game theory. Nowadays, game theory can find its applications in machine learning, and other fields. Typical examples can be multi-agent scenarios, e.g. multi-agent reinforcement learning etc.. That is why we submit the paper. We think it's a good idea for NIPS to encourage papers from other research fields, so the inter-discipline research can be more frequent within the community, and becomes more easily for the researchers. Thanks!
As to the documents, the one with more pages is the complete version of our paper. As NIPS accepts only eight pages excluding cited references, the paper with less pages is our submitted version. Thanks a lot for your kind review.

